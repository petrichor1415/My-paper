# My-paper
## 基于CLIP模型的改进（分类）
**1、[2019]MixMatch: A Holistic Approach to Semi-Supervised Learning**[[Paper]](https://arxiv.org/pdf/1905.02249)[[Code]](https://github.com/google-research/mixmatch)
  

**2、[ICML 2021]CLIP：Learning Transferable Visual Models From Natural Language Supervision**[[Paper]](https://arxiv.org/pdf/2103.00020)[[Code]](https://github.com/OpenAI/CLIP)

**3、[2021 ]CLIP-Adapter: Better Vision-Language Models with Feature Adapters**[[Paper]](https://arxiv.org/pdf/2110.04544)[[Code]](https://github.com/gaopengcuhk/CLIP-Adapter0)



**4、[ECCV 2022]Visual Prompt Tuning**
[[Paper]](https://arxiv.org/abs/2203.12119)
[[Code]](https://github.com/kmnp/vpt)

**5、[CVPR 2022]CoOp:Prompt Learning for Vision-Language Models**
[[Paper]](https://arxiv.org/pdf/2109.01134)
[[Code]](https://github.com/KaiyangZhou/CoOp)


**6、[CVPR 2023]Task Residual for Tuning Vision-Language Models**
[[Paper]](https://arxiv.org/pdf/2211.10277)
[[Code]](https://github.com/geekyutao/TaskRes)


**7、[2023]UP-Adapter:Unsupervised Prototype Adapter for Vision-Language Models**
[[Paper]](https://arxiv.org/pdf/2308.11507)



**8、[2023 NeurIPS]LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and Unlabeled Image Collections**
[[Paper]](https://arxiv.org/pdf/2305.18287)
[[Code]](https://github.com/jmiemirza/LaFTer)


**9、[2024 CVPR]Systematic comparison of semi-supervised and self-supervised learning for medical image classification**
[[Paper]](https://arxiv.org/pdf/2307.08919)
[[Code]](https://github.com/tufts-ml/SSL-vs-SSL-benchmark)

**10、[CVPR 2024] Official PyTorch Code for "PromptKD: Unsupervised Prompt Distillation for Vision-Language Models**
[[Paper]](https://arxiv.org/pdf/2403.02781)
[[Code]](https://github.com/zhengli97/PromptKD)



## 分割
### Open-Vocabulary Semantic Segmentation
**1、[2022 ECCV]Mask CLIP:Extract Free Dense Labels from CLIP**
[[Paper]](https://arxiv.org/pdf/2112.01071)
[[Code]](https://github.com/chongzhou96/MaskCLIP)


**2、[2022 ICLR]LANGUAGE-DRIVEN SEMANTIC SEGMENTATION**
[[Paper]](https://arxiv.org/pdf/2201.03546)
[[Code]](https://github.com/isl-org/lang-seg)

  

**3、[2024 ICLR] CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction**
[[Paper]](https://arxiv.org/abs/2310.01403)
[[Code]](https://github.com/wusize/CLIPSelf)



**4、[2024 CVPR] SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation**
[[Paper]](https://arxiv.org/abs/2311.15537)
[[Code]](https://github.com/xb534/SED.git)


**5、[2024 ECCV] CLIP-DINOiser: Teaching CLIP a few DINO tricks for open-vocabulary semantic segmentation**
[[Paper]](https://arxiv.org/pdf/2312.12359)
[[Code]](https://github.com/wysoczanska/clip_dinoiser)


**6、[2024 ECCV] ProxyCLIP: Proxy Attention Improves CLIP for Open-Vocabulary Segmentation**
[[Paper]](https://arxiv.org/pdf/2408.04883)
[[Code]](https://github.com/mc-lan/ProxyCLIP)


**7、[2024 ECCV] Pay Attention to Your Neighbours: Training-Free Open-Vocabulary Semantic Segmentation**
[[Paper]](https://arxiv.org/pdf/2404.08181)
[[Code]](https://github.com/sinahmr/NACLIP)


**8、[2024 ECCV] ClearCLIP: Decomposing CLIP Representations for Dense Vision-Language Inference**
[[Paper]](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06346.pdf)
[[Code]](https://github.com/mc-lan/ClearCLIP)


**9、[2024 ECCV] SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference**
[[Paper]](https://arxiv.org/pdf/2312.01597)
[[Code]](https://github.com/wangf3014/SCLIP)

  
**10、[CVPR2024] Open-world Semantic Segmentation Including Class Similarity**
[[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Sodano_Open-World_Semantic_Segmentation_Including_Class_Similarity_CVPR_2024_paper.pdf)
[[Code]](https://github.com/PRBonn/ContMAV)


**11、[CVPR2024]Not All Classes Stand on Same Embeddings:Calibrating a Semantic Distance with Metric Tensor** [[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Park_Not_All_Classes_Stand_on_Same_Embeddings_Calibrating_a_Semantic_CVPR_2024_paper.pdf)
[[Code]]

**12、[CVPR 2024] DuPL: Dual Student with Trustworthy Progressive Learning for Robust Weakly Supervised Semantic Segmentation**
[[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_DuPL_Dual_Student_with_Trustworthy_Progressive_Learning_for_Robust_Weakly_CVPR_2024_paper.pdf)
[[Code]](https://github.com/Wu0409/DuPL)

**13、[CVPR 2024]Hunting Attributes: Context Prototype-Aware Learning for Weakly Supervised Semantic Segmentation**
[[Paper]](https:https://openaccess.thecvf.com/content/CVPR2024/papers/Tang_Hunting_Attributes_Context_Prototype-Aware_Learning_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper.pdf)
[[Code]](https://github.com/Barrett-python/CPAL)


**14、[CVPR 2024]Improving the Generalization of Segmentation Foundation Model under Distribution Shift via Weakly Supervised Adaptation**
[[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Improving_the_Generalization_of_Segmentation_Foundation_Model_under_Distribution_Shift_CVPR_2024_paper.pdf)

**15、[CVPR 2024]USE: Universal Segment Embeddings for Open-Vocabulary Image Segmentation**
[[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_USE_Universal_Segment_Embeddings_for_Open-Vocabulary_Image_Segmentation_CVPR_2024_paper.pdf)

**16、[CVPR 2024]ReCLIP++:Learn to Rectify the Bias of CLIP for Unsupervised Semantic Segmentation**
[[Paper]](https://arxiv.org/pdf/2408.06747)
[[Code]](https://github.com/dogehhh/ReCLIP)


**17、[CVPR2024]Official code for Class Tokens Infusion for Weakly Supervised Semantic Segmentation**
[[Paper]](Yoon_Class_Tokens_Infusion_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper)
[[Code]](https://github.com/yoon307/CTI)


**18、[CVPR 2024]CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation**
[[Paper]](https://arxiv.org/pdf/2303.11797)
[[Code]](https://github.com/cvlab-kaist/CAT-Seg)

  
**19、[CVPR 2024]CuVLER: Enhanced Unsupervised Object Discoveries through Exhaustive Self-Supervised Transformers**
[[Paper]](https://arxiv.org/pdf/2403.07700)
[[Code]](https://github.com/shahaf-arica/CuVLER?tab=readme-ov-file)
  
### Weakly Supervised Semantic Segmentation
**1、[ICCV 2023]Spatial-Aware Token for Weakly Supervised Object Localization** [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial-Aware_Token_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf) [[code]](https://github.com/khanrc/tcl)

**2、[CVPR 2023]Learning Multi-Modal Class-Specific Tokens for Weakly Supervised Dense Object Localization** [[paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Learning_Multi-Modal_Class-Specific_Tokens_for_Weakly_Supervised_Dense_Object_Localization_CVPR_2023_paper.pdf) [[code]](https://github.com/xulianuwa/MMCST)

**3、[CVPR 2024]Frozen CLIP: A Strong Backbone for Weakly Supervised Semantic Segmentation** [[paper]](https://arxiv.org/pdf/2406.11189v1) [[code]](https://github.com/zbf1991/WeCLIP)

**4、[CVPR 2024]DuPL: Dual Student with Trustworthy Progressive Learning for RobustWeakly Supervised Semantic Segmentation** [[paper]](https://arxiv.org/pdf/2403.11184)[[code]](https://github.com/Wu0409/DuPL)

**5、[CVPR 2024]Hunting Attributes: Context Prototype-Aware Learning for Weakly Supervised Semantic Segmentation** [[paper]](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2403.07630)[[code]](https://github.com/Barrett-python/CPAL))

**6、[AAAI 2025]MoRe: Class Patch Attention Needs Regularization for Weakly Supervised Semantic Segmentation**[[paper]](https://arxiv.org/pdf/2412.11076)[[code]](https://github.com/zwyang6/MoRe)


**7、[ECCV 2024]DIAL: Dense Image-text ALignment for Weakly Supervised Semantic Segmentation**[[paper]](https://arxiv.org/pdf/2409.15801)

**8、[CVPR 2023]ToCo:Token Contrast for Weakly-Supervised Semantic Segmentation**[[paper]](https://arxiv.org/pdf/2303.01267)[[code]](https://github.com/rulixiang/ToCo)

**9、[CVPR 2024]Separate and Conquer: Decoupling Co-occurrence via Decomposition and Representation for Weakly Supervised Semantic Segmentation**[[paper]](https://arxiv.org/pdf/2402.18467)[[code]](https://github.com/zwyang6/SeCo)

**10、[ECCV 2024]CoSa:Weakly Supervised Co-training with Swapping Assignments for Semantic Segmentation**[[paper]](https://arxiv.org/pdf/2402.17891)[[code]](https://github.com/youshyee/CoSA)

**10、[IEEE 2024]SSC:Spatial Structure Constraints for Weakly Supervised Semantic Segmentation**[[paper]](https://arxiv.org/pdf/2401.11122)[[code](https://github.com/NUST-Machine-Intelligence-Laboratory/SSC)

**11、[AAAI 2024]Progressive Feature Self-Reinforcement for Weakly Supervised Semantic Segmentation**[[paper]](https://arxiv.org/pdf/2312.08916)[[code]](https://github.com/Jessie459/feature-self-reinforcement)

**12、[CVPR 2022]MCTFormer:Multi-Class Token Transformer for Weakly Supervised Semantic Segmentation**[[paper]](https://arxiv.org/pdf/2203.02891)[[code]](https://github.com/xulianuwa/MCTformer)

**13、[CVPR 2023]Boundary-enhanced Co-training for Weakly Supervised Semantic Segmentation**[[paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Rong_Boundary-Enhanced_Co-Training_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf)[[code]](https://github.com/ShenghaiRong/BECO?tab=readme-ov-file)

**14、[CVPR 2022] MCTformer+: Multi-Class Token Transformer for Weakly Supervised Semantic Segmentation**[[paper]](https://arxiv.org/pdf/2308.03005)[[code]](https://github.com/xulianuwa/MCTformer)

**15、[CVPR 2024]Class Tokens Infusion for Weakly Supervised Semantic Segmentation**[[paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Yoon_Class_Tokens_Infusion_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper.pdf)[[code]]( https://github.com/yoon307/CTI)

**16、[CVPR 2024]SFC: Shared Feature Calibration in Weakly Supervised Semantic Segmentation**[[paper]](https://arxiv.org/pdf/2401.11719)[[code]](https://github.com/Barrett-python/SFC)

**17、[CVPR 2024]PSDPM:Prototype-based Secondary Discriminative Pixels Mining for Weakly Supervised Semantic Segmentation**[[paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_PSDPM_Prototype-based_Secondary_Discriminative_Pixels_Mining_for_Weakly_Supervised_Semantic_CVPR_2024_paper.pdf)[[code]](https://github.com/xinqiaozhao/PSDPM)

**18、[CVPR 2022]Learning Affinity from Attention: End-to-End Weakly-Supervised Semantic Segmentation with Transformers**[[paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Ru_Learning_Affinity_From_Attention_End-to-End_Weakly-Supervised_Semantic_Segmentation_With_Transformers_CVPR_2022_paper.pdf)[[code]](https://github.com/rulixiang/afa)





### Weakly Supervised Object Localization
**1、[2024]A Realistic Protocol for Evaluation of Weakly Supervised Object Localization**[[paper](https://arxiv.org/pdf/2404.10034)[[code]](https://github.com/shakeebmurtaza/wsol_model_selection)


### Unsupervised Semantic Segmentation

  
## 目标检测（Object Detection）
**1、[CVPR 2024]Object Recognition as Next Token Prediction**
[[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Yue_Object_Recognition_as_Next_Token_Prediction_CVPR_2024_paper.pdf)
[[Code]](https://github.com/kaiyuyue/nxtp)


**2、[CVPR 2025]LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of Large Language Models**
[[Paper]](https://arxiv.org/pdf/2501.18954)
[[Code]](https://github.com/iSEE-Laboratory/LLMDet)



## 聚类
**1、[ICML 2024]Image Clustering with External Guidance**[[paper]](https://arxiv.org/pdf/2310.11989)[[code]](https://github.com/XLearning-SCU/2024-ICML-TAC)



## 医学图像
**1、[CVPR 2025]PH-Net: Semi-Supervised Breast Lesion Segmentation via Patch-wise Hardness**
[[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Jiang_PH-Net_Semi-Supervised_Breast_Lesion_Segmentation_via_Patch-wise_Hardness_CVPR_2024_paper.pdf)
[[Code]](https://github.com/jjjsyyy/PH-Net)

**2、[CVPR 2024[Highlight] Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images**
[[Paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_Adapting_Visual-Language_Models_for_Generalizable_Anomaly_Detection_in_Medical_Images_CVPR_2024_paper.pdf)
[[Code]](https://github.com/MediaBrain-SJTU/MVFA-AD)

**3、[CVPR 2024]GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation** [[paper]](https://arxiv.org/pdf/2411.13147v1) [[code]](https://github.com/ZiqinZhou66/ZegCLIP?tab=readme-ov-file)

## BackBone
**1、[CVPR 2016] CAM:Learning Deep Features for Discriminative Localization**
[[paper]](https://arxiv.org/pdf/1512.04150)

**2、[ICCV 2021] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows**
[[paper]](https://arxiv.org/pdf/2103.14030)[[code]](https://github.com/microsoft/Swin-Transformer)
##  (数据集)Dataset

