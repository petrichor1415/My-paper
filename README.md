# My-paper
## 基于CLIP模型的改进（分类）
**1、[2019]MixMatch: A Holistic Approach to Semi-Supervised Learning**
- Paper:https://arxiv.org/pdf/1905.02249
- Code:https://github.com/google-research/mixmatch
- Innovate:
  

**2、[ICML 2021]CLIP：Learning Transferable Visual Models From Natural Language Supervision**
- Paper:https://arxiv.org/pdf/2103.00020
- Code:https://github.com/OpenAI/CLIP
- Innovate:Text-image contrast and training.

**3、[2021 ]CLIP-Adapter: Better Vision-Language Models with Feature Adapters**
- Paper:https://arxiv.org/pdf/2110.04544
- Code:https://github.com/gaopengcuhk/CLIP-Adapter
- Innovate:


**4、[ECCV 2022]Visual Prompt Tuning**
- Paper:https://arxiv.org/abs/2203.12119
- Code:https://github.com/kmnp/vpt
- Innovate:

**5、[CVPR 2022]CoOp:Prompt Learning for Vision-Language Models**
- Paper:https://arxiv.org/pdf/2109.01134
- Code:https://github.com/KaiyangZhou/CoOp.
- Innovate:

**6、[CVPR 2023]Task Residual for Tuning Vision-Language Models**
- Paper:https://arxiv.org/pdf/2211.10277
- Code:https://github.com/geekyutao/TaskRes
- Innovate:

**7、[2023]UP-Adapter:Unsupervised Prototype Adapter for Vision-Language Models**
- Paper:https://arxiv.org/pdf/2308.11507
- Code:
- Innovate:


**8、[2023 NeurIPS]LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and Unlabeled Image Collections**
- Paper:https://arxiv.org/pdf/2305.18287
- Code:https://github.com/jmiemirza/LaFTer
- Innovate:

**9、[2024 CVPR]Systematic comparison of semi-supervised and self-supervised learning for medical image classification**
- Paper:https://arxiv.org/pdf/2307.08919
- Code:https://github.com/tufts-ml/SSL-vs-SSL-benchmark
- Innovate:

**10、[CVPR 2024] Official PyTorch Code for "PromptKD: Unsupervised Prompt Distillation for Vision-Language Models**
- Paper:https://arxiv.org/pdf/2403.02781
- Code:https://github.com/zhengli97/PromptKD
- Innovate:


## 分割
### Open-Vocabulary Semantic Segmentation
**1、[2022 ECCV]Mask CLIP:Extract Free Dense Labels from CLIP**
- Paper:https://arxiv.org/pdf/2112.01071
- Code:https://github.com/chongzhou96/MaskCLIP
- Innovate:The MaskCLIP and MaskCLIP + models are proposed.

**2、[2022 ICLR]LANGUAGE-DRIVEN SEMANTIC SEGMENTATION**
- Paper:https://arxiv.org/pdf/2201.03546
- Code:https://github.com/isl-org/lang-seg
- Innovate:Image encoder: based on dense prediction transformer (DPT).
- 

**3、[2024 ICLR] CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction**
- Paper:https://arxiv.org/abs/2310.01403
- Code:https://github.com/wusize/CLIPSelf
- Innovate:No text is required, and the image is cropped to align with the full image.


**4、[2024 CVPR] SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation**
- Paper:https://arxiv.org/abs/2311.15537
- Code:https://github.com/xb534/SED.git.
- Innovate:A hierarchical encoder and progressive fusion feature are used, as well as early category rejection.

**5、[2024 ECCV] CLIP-DINOiser: Teaching CLIP a few DINO tricks for open-vocabulary semantic segmentation**
- Paper:https://arxiv.org/pdf/2312.12359
- Code:https://github.com/wysoczanska/clip_dinoiser
- Innovate:The positioning prior information of DINO is introduced to guide the pooling of MaskCLIP and features.

**6、[2024 ECCV] ProxyCLIP: Proxy Attention Improves CLIP for Open-Vocabulary Segmentation**
- Paper:https://arxiv.org/pdf/2408.04883
- Code:https://github.com/mc-lan/ProxyCLIP
- Innovate:

**7、[2024 ECCV] Pay Attention to Your Neighbours: Training-Free Open-Vocabulary Semantic Segmentation**
- Paper:https://arxiv.org/pdf/2404.08181
- Code:https://github.com/sinahmr/NACLIP
- Innovate:

**8、[2024 ECCV] ClearCLIP: Decomposing CLIP Representations for Dense Vision-Language Inference**
- Paper:https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06346.pdf
- Code:https://github.com/mc-lan/ClearCLIP
- Innovate:

**9、[2024 ECCV] SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference**
- Paper:https://arxiv.org/pdf/2312.01597
- Code:https://github.com/wangf3014/SCLIP
- Innovate:
  
**10、[CVPR2024] Open-world Semantic Segmentation Including Class Similarity**
- Paper:https://openaccess.thecvf.com/content/CVPR2024/papers/Sodano_Open-World_Semantic_Segmentation_Including_Class_Similarity_CVPR_2024_paper.pdf
- Code:https://github.com/PRBonn/ContMAV
- Innovate:

**11、[CVPR2024]Not All Classes Stand on Same Embeddings:Calibrating a Semantic Distance with Metric Tensor**
- Paper:https://openaccess.thecvf.com/content/CVPR2024/papers/Park_Not_All_Classes_Stand_on_Same_Embeddings_Calibrating_a_Semantic_CVPR_2024_paper.pdf
- Code:
- Innovate:

**12、[CVPR 2024] DuPL: Dual Student with Trustworthy Progressive Learning for Robust Weakly Supervised Semantic Segmentation**
- Paper:https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_DuPL_Dual_Student_with_Trustworthy_Progressive_Learning_for_Robust_Weakly_CVPR_2024_paper.pdf
- Code:https://github.com/Wu0409/DuPL
- Innovate

**13、[CVPR 2024]Hunting Attributes: Context Prototype-Aware Learning for Weakly Supervised Semantic Segmentation**
- Paper:https:https://openaccess.thecvf.com/content/CVPR2024/papers/Tang_Hunting_Attributes_Context_Prototype-Aware_Learning_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper.pdf
- Code:https://github.com/Barrett-python/CPAL
- Innovate

**14、[CVPR 2024]Improving the Generalization of Segmentation Foundation Model under Distribution Shift via Weakly Supervised Adaptation**
- Paper:https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Improving_the_Generalization_of_Segmentation_Foundation_Model_under_Distribution_Shift_CVPR_2024_paper.pdf
- Code:
- Innovate

**15、[CVPR 2024]USE: Universal Segment Embeddings for Open-Vocabulary Image Segmentation**
- Paper:https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_USE_Universal_Segment_Embeddings_for_Open-Vocabulary_Image_Segmentation_CVPR_2024_paper.pdf
- Code:
- Innovate

**16、[CVPR 2024]ReCLIP++:Learn to Rectify the Bias of CLIP for Unsupervised Semantic Segmentation**
- Paper:https://arxiv.org/pdf/2408.06747
- Code:https://github.com/dogehhh/ReCLIP
- Innovate


**17、[CVPR2024]Official code for Class Tokens Infusion for Weakly Supervised Semantic Segmentation**
- Paper:Yoon_Class_Tokens_Infusion_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper
- Code:https://github.com/yoon307/CTI
- Innovate

**18、[CVPR 2024]CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation**
- Paper:https://arxiv.org/pdf/2303.11797
- Code:https://github.com/cvlab-kaist/CAT-Seg
- Innovate
  
**19、[CVPR 2024]CuVLER: Enhanced Unsupervised Object Discoveries through Exhaustive Self-Supervised Transformers**
- Paper:https://arxiv.org/pdf/2403.07700
- Code:https://github.com/shahaf-arica/CuVLER?tab=readme-ov-file
- Innovate
  
  
## 目标检测（Object Detection）
**1、[CVPR 2024]Object Recognition as Next Token Prediction**
- Paper:https://openaccess.thecvf.com/content/CVPR2024/papers/Yue_Object_Recognition_as_Next_Token_Prediction_CVPR_2024_paper.pdf
- Code:https://github.com/kaiyuyue/nxtp
- Innovate:




**2、[CVPR 2025]LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of Large Language Models**
- Paper:https://arxiv.org/pdf/2501.18954
- Code:https://github.com/iSEE-Laboratory/LLMDet
- Innovate:LLM generates image level and region level descriptions.


### Supervised Semantic Segmentation
### Weakly Supervised Semantic Segmentation

### Unsupervised Semantic Segmentation



## 医学图像
**1、[CVPR 2025]PH-Net: Semi-Supervised Breast Lesion Segmentation via Patch-wise Hardness**
- Paper:https://openaccess.thecvf.com/content/CVPR2024/papers/Jiang_PH-Net_Semi-Supervised_Breast_Lesion_Segmentation_via_Patch-wise_Hardness_CVPR_2024_paper.pdf
- Code:https://github.com/jjjsyyy/PH-Net
- Innovate:

**2、[CVPR 2024[Highlight] Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images**
- Paper:https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_Adapting_Visual-Language_Models_for_Generalizable_Anomaly_Detection_in_Medical_Images_CVPR_2024_paper.pdf
- Code:https://github.com/MediaBrain-SJTU/MVFA-AD
- Innovate:

## BackBone
##  (数据集)Dataset

